{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLbP9pCD9sHnnOSAipNH5/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Testing a model using neural networks"
      ],
      "metadata": {
        "id": "v04qEMLw-XuU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "epG016j3-QSs"
      },
      "outputs": [],
      "source": [
        "# Packages used for developing models, as well as processing information\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from warnings import filterwarnings\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.pipeline import Pipeline,make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Reading the database and checking some information\n",
        "#I purposely eliminated some information from the data set so that I could apply methods to fill\n",
        "#in empty fields and transform text data into numeric values.\n",
        "\n",
        "Dataset = pd.read_csv('breast_cancer.csv',sep=';', on_bad_lines='skip')\n",
        "#Dataset.info()\n",
        "#Dataset.describe()"
      ],
      "metadata": {
        "id": "x9ZKLh-E-jkY"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking Some Measurements"
      ],
      "metadata": {
        "id": "JL8_sw08_aRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(font_scale=1.5,rc={'figure.figsize':(20,20)}) #usando a biblioteca sns posso verificar algumas distribuições dos meus dados\n",
        "eixo=Dataset.hist(bins=20,color='red')"
      ],
      "metadata": {
        "id": "ZZ_mPTmy-jmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing Some Variables"
      ],
      "metadata": {
        "id": "WFub0Wuk_lTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class processing_data:\n",
        "  def __init__(self,base=None,label='Processing Dataset'):\n",
        "    self.base = base\n",
        "    self.label = label\n",
        "\n",
        "  # select objetc columns and transform into float values\n",
        "  def float_values(self,str_var):\n",
        "    textos =self.base.select_dtypes(include=['object']).columns\n",
        "    for column in textos:\n",
        "      if column not in str_var:\n",
        "        self.base[column] = self.base[column].str.replace(',', '.').astype(float)\n",
        "    self.base.select_dtypes(include=['object']).columns\n",
        "    return self.base\n",
        "\n",
        "  #if my target is a text I transform in dummy value\n",
        "  def target_variable(self,target,variavel):\n",
        "    #base = pd.Series(base)\n",
        "    self.base[target] = np.where(self.base[target]==variavel, 1, 0)\n",
        "    return self.base\n",
        "\n",
        "  # transform in dummies some variables\n",
        "  def dummy_df(self,X,dummies):\n",
        "      X = pd.get_dummies(X, prefix=dummies, columns=dummies,dtype='int')\n",
        "      return X\n",
        "\n",
        "  def normalize_df(self,X,Lista_variaveis):\n",
        "    #Normalize the data\n",
        "    X =pd.DataFrame(data=X, columns=Lista_variaveis)\n",
        "    min_max_scaler =MinMaxScaler()\n",
        "    X = min_max_scaler.fit_transform(X)\n",
        "    return X\n",
        "\n"
      ],
      "metadata": {
        "id": "dUQ-n9Md-jpw"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = processing_data(base=Dataset)\n",
        "processor.float_values(['Family Case','target'])\n",
        "processor.target_variable('target','Malignant')\n",
        "processor.dummy_df(Dataset,['Family Case'])\n",
        "processor.base=processor.dummy_df(processor.base,['Family Case'])\n",
        "\n",
        "column_to_move = processor.base.pop(\"target\")\n",
        "processor.base['target'] = column_to_move\n",
        "\n",
        "X=processor.base.iloc[:,:-1].values\n",
        "y=processor.base.iloc[:,-1].values\n"
      ],
      "metadata": {
        "id": "u_Pv5vBw6kCQ"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In this step I select my data set and transform other text variables into numeric ones to facilitate the processing of my model.\n",
        "# Get the indices of columns with missing values\n",
        "missing_cols_indices = [Dataset.columns.get_loc(col) for col in Dataset.columns[Dataset.isna().any()]]\n",
        "\n",
        "# Impute missing values using these indices\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer = imputer.fit(X[:, missing_cols_indices])\n",
        "X[:, missing_cols_indices] = imputer.transform(X[:, missing_cols_indices])\n"
      ],
      "metadata": {
        "id": "XB4267bK-jvA"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Lista_variaveis=Lista_variaveis = processor.base.columns[:-1]\n",
        "X=processor.normalize_df(X,Lista_variaveis)\n"
      ],
      "metadata": {
        "id": "k6SDHkJE6uvS"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Development and Results"
      ],
      "metadata": {
        "id": "N2olQUyGCiBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Neural Network Model\n",
        "\n",
        "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "# Convert ytrain and ytest to integer labels before fitting\n",
        "ytrain = ytrain.astype(int) # Convert to integer type to avoid \"unknown label type\" error.\n",
        "ytest = ytest.astype(int) # Convert to integer type to avoid \"unknown label type\" error.\n",
        "\n",
        "num_neu= len(Lista_variaveis)\n",
        "targ=2\n",
        "ocult_neu=int((num_neu*(2/3))+2)\n",
        "\n",
        "neuro=tf.keras.models.Sequential([tf.keras.layers.Dense(num_neu,input_shape=(len(Lista_variaveis),)\n",
        "                                               ,activation='relu',kernel_initializer='he_normal'),\n",
        "                           tf.keras.layers.Dropout(0.5),\n",
        "                           tf.keras.layers.Dense(ocult_neu,activation='relu',kernel_initializer='he_normal'),\n",
        "                           tf.keras.layers.Dropout(0.5),\n",
        "                           tf.keras.layers.Dense(2, activation='softmax')])"
      ],
      "metadata": {
        "id": "zpXOEQjq-jxZ"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train setings\n",
        "neuro.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), #or binary_crossentropy\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_CtK66Jb-j0I"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 4\n",
        "EPOCHS = 15"
      ],
      "metadata": {
        "id": "lfOALu8i-j25"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuro.fit(Xtrain, ytrain, batch_size=BATCH_SIZE, epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA4XhQ0P-j5Z",
        "outputId": "e5a20ce2-5ca5-42b7-a927-2bf0c2212272"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5054 - loss: 0.7777\n",
            "Epoch 2/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.6835\n",
            "Epoch 3/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7615 - loss: 0.5296\n",
            "Epoch 4/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7987 - loss: 0.4380\n",
            "Epoch 5/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.3946\n",
            "Epoch 6/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8562 - loss: 0.3512\n",
            "Epoch 7/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.3411\n",
            "Epoch 8/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.2709\n",
            "Epoch 9/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9013 - loss: 0.2445\n",
            "Epoch 10/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2577\n",
            "Epoch 11/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2211\n",
            "Epoch 12/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.1816\n",
            "Epoch 13/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9522 - loss: 0.1526\n",
            "Epoch 14/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1632\n",
            "Epoch 15/15\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 0.1970\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b76626e3250>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuro.evaluate(Xtest, ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gccrXrRI-j8R",
        "outputId": "71b448a8-55bb-441a-ba69-463c01c5621e"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9787 - loss: 0.0753  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10502660274505615, 0.9649122953414917]"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = np.round(neuro.predict(Xtest, verbose=0)[:,1], 7)\n",
        "fpr, tpr, thresholds = roc_curve(ytest, probs)\n",
        "#Performs the two-sample Kolmogorov-Smirnov test for goodness of fit.\n",
        "#This test compares the underlying continuous distributions F(x) and G(x) of two independent samples\n",
        "print('KS  Validation: {0:.2f}% e AUC: {1:.2f}%'.format(stats.ks_2samp(fpr, tpr)[0] * 100.0, auc(fpr, tpr) * 100))\n",
        "print((probs.max(),probs.min()))\n",
        "\n",
        "probs = np.round(neuro.predict(Xtrain, verbose=0)[:,1], 7)\n",
        "fpr, tpr, thresholds = roc_curve(ytrain, probs)\n",
        "print('KS Development: {0:.2f}% e AUC: {1:.2f}%'.format(stats.ks_2samp(fpr, tpr)[0] * 100.0, auc(fpr, tpr) * 100))\n",
        "print((probs.max(),probs.min()))\n",
        "\n",
        "\n",
        "\n",
        "# Define a scoring function for permutation_importance\n",
        "def scoring_fn(estimator, X, y):\n",
        "    y_pred = np.argmax(estimator.predict(X, verbose=0), axis=1)  # Get predicted classes\n",
        "    return accuracy_score(y, y_pred)  # Calculate accuracy\n",
        "\n",
        "# Calculate permutation feature importance using the scoring function\n",
        "result = permutation_importance(\n",
        "    neuro, Xtest, ytest, n_repeats=10, random_state=0, scoring=scoring_fn\n",
        ")\n",
        "# Create a DataFrame to store the results\n",
        "feature_importances = pd.DataFrame(\n",
        "    {\n",
        "        \"feature\": Lista_variaveis,  # Assuming Lista_variaveis contains feature names\n",
        "        \"importance\": result.importances_mean,\n",
        "    }\n",
        ").sort_values(\"importance\", ascending=False)\n",
        "\n",
        "\n",
        "print(feature_importances) # Print the top 5 most important features or change the number to see others"
      ],
      "metadata": {
        "id": "Mje4WbTYH275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654dd439-792d-4c6a-d04e-fcaffa86ab50"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KS  Validation: 66.67% e AUC: 99.36%\n",
            "(np.float32(0.9999983), np.float32(1e-07))\n",
            "KS Development: 80.00% e AUC: 99.39%\n",
            "(np.float32(0.9999956), np.float32(3e-07))\n",
            "                       feature  importance\n",
            "30              Family Case_no    0.078947\n",
            "6               mean concavity    0.028947\n",
            "27        worst concave points    0.019298\n",
            "0                  mean radius    0.014035\n",
            "32             Family Case_yes    0.013158\n",
            "7          mean concave points    0.011404\n",
            "23                  worst area    0.009649\n",
            "15           compactness error    0.007895\n",
            "28              worst symmetry    0.006140\n",
            "29     worst fractal dimension    0.005263\n",
            "22             worst perimeter    0.004386\n",
            "31  Family Case_no information    0.004386\n",
            "12             perimeter error    0.004386\n",
            "9       mean fractal dimension    0.002632\n",
            "10                radius error    0.001754\n",
            "8                mean symmetry    0.001754\n",
            "13                  area error    0.001754\n",
            "3                    mean area    0.000877\n",
            "19     fractal dimension error    0.000000\n",
            "25           worst compactness    0.000000\n",
            "18              symmetry error    0.000000\n",
            "4              mean smoothness    0.000000\n",
            "16             concavity error    0.000000\n",
            "11               texture error    0.000000\n",
            "20                worst radius    0.000000\n",
            "26             worst concavity    0.000000\n",
            "21               worst texture   -0.000877\n",
            "1                 mean texture   -0.000877\n",
            "2               mean perimeter   -0.001754\n",
            "5             mean compactness   -0.002632\n",
            "14            smoothness error   -0.003509\n",
            "24            worst smoothness   -0.003509\n",
            "17        concave points error   -0.003509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=neuro.predict(X, verbose=0)\n",
        "y_pred = [np.argmax(v) for v in y_pred]\n",
        "X1 = min_max_scaler.inverse_transform(X)\n",
        "df = pd.DataFrame(data=X1, columns=Lista_variaveis)\n",
        "df2 = pd.DataFrame(data=y,columns=['Tarq'])\n",
        "df3 = pd.DataFrame(data=y_pred,columns=['Pred'])\n",
        "df = pd.concat([df,df2,df3],axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "_Z2CJ0RXJ-Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34i-TYT34G26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Pipelines\n"
      ],
      "metadata": {
        "id": "JZ6QyoLe4H3q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dM6oYEFZ4HQK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}